{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHYHXXnRRXjJ"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZtKBXwGRXjL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "NvkV87nbmV_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in data from prepared file."
      ],
      "metadata": {
        "id": "Ynqh31sTmbi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('df_prepped.csv')\n",
        "pd.set_option('display.max_columns', None)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "tejmkkMOV-mq",
        "outputId": "8e42a839-ebe4-462a-cb47-0e5d6fcc5c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Year Countries  Sand_1  Sand_2  Sand_3  Sand_4  Sand_5  Sand_6  Sand_7  \\\n",
              "0      2007    Angola      50      51      51      48      45      46      46   \n",
              "1      2007    Angola      62      64      63      59      58      59      59   \n",
              "2      2007    Angola      69      71      70      67      65      65      66   \n",
              "3      2007    Angola      60      63      61      57      53      53      53   \n",
              "4      2007    Angola      67      69      68      63      61      61      61   \n",
              "...     ...       ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "32325  2016  Zimbabwe      73      75      74      69      66      66      66   \n",
              "32326  2016  Zimbabwe      57      58      58      54      52      51      52   \n",
              "32327  2016  Zimbabwe      55      57      56      54      52      51      51   \n",
              "32328  2016  Zimbabwe      70      72      71      67      63      63      62   \n",
              "32329  2016  Zimbabwe      62      64      63      60      59      60      60   \n",
              "\n",
              "       Clay_1  Clay_2  Clay_3  Clay_4  Clay_5  Clay_6  Clay_7  OC_1  OC_2  \\\n",
              "0          37      35      36      39      42      42      42  0.52  0.23   \n",
              "1          27      25      26      29      31      30      30  0.11  0.05   \n",
              "2          19      16      18      21      24      24      23  0.09  0.06   \n",
              "3          29      26      28      32      35      36      36  0.46  0.16   \n",
              "4          22      19      21      25      28      28      29  0.15  0.09   \n",
              "...       ...     ...     ...     ...     ...     ...     ...   ...   ...   \n",
              "32325      20      18      20      24      27      27      27  0.10  0.08   \n",
              "32326      28      26      26      31      33      34      33  0.14  0.12   \n",
              "32327      30      28      30      32      34      35      35  0.53  0.41   \n",
              "32328      17      14      15      20      24      24      24  0.14  0.09   \n",
              "32329      24      22      24      27      29      28      28  0.08  0.06   \n",
              "\n",
              "       OC_3  OC_4  OC_5  OC_6  OC_7  PAW_1  PAW_2  PAW_3  PAW_4  PAW_5  PAW_6  \\\n",
              "0      0.17  0.09  0.04  0.02  0.02   0.15   0.15   0.14   0.13   0.10   0.07   \n",
              "1      0.07  0.04  0.02  0.02  0.01   0.11   0.10   0.10   0.09   0.07   0.07   \n",
              "2      0.07  0.04  0.02  0.02  0.02   0.10   0.10   0.10   0.09   0.07   0.07   \n",
              "3      0.14  0.08  0.05  0.04  0.03   0.12   0.13   0.12   0.12   0.11   0.10   \n",
              "4      0.09  0.05  0.02  0.01  0.01   0.11   0.11   0.11   0.11   0.08   0.04   \n",
              "...     ...   ...   ...   ...   ...    ...    ...    ...    ...    ...    ...   \n",
              "32325  0.08  0.04  0.02  0.01  0.01   0.09   0.10   0.09   0.09   0.07   0.04   \n",
              "32326  0.10  0.05  0.03  0.01  0.01   0.13   0.14   0.13   0.11   0.09   0.03   \n",
              "32327  0.30  0.22  0.18  0.16  0.15   0.18   0.19   0.17   0.15   0.14   0.14   \n",
              "32328  0.10  0.06  0.04  0.03  0.03   0.10   0.10   0.10   0.10   0.09   0.09   \n",
              "32329  0.06  0.03  0.02  0.01  0.01   0.11   0.11   0.11   0.09   0.08   0.04   \n",
              "\n",
              "       PAW_7  Y_maize_major           Farm  Sow_Maize_month_int  \\\n",
              "0       0.07       0.615357     104_Angola                    9   \n",
              "1       0.03       0.257656      99_Angola                    9   \n",
              "2       0.07       4.286831     108_Angola                    9   \n",
              "3       0.09       0.700384     102_Angola                    9   \n",
              "4       0.04       0.553450      43_Angola                    9   \n",
              "...      ...            ...            ...                  ...   \n",
              "32325   0.04       0.674080  3874_Zimbabwe                    5   \n",
              "32326   0.03       0.707797  3875_Zimbabwe                    5   \n",
              "32327   0.14       0.805844  3859_Zimbabwe                    5   \n",
              "32328   0.08       0.595883  3871_Zimbabwe                    5   \n",
              "32329   0.04       0.846773  3869_Zimbabwe                    5   \n",
              "\n",
              "       Harvest_Maize_month_int  sow_to_harvest_months  maize_lag-1  \\\n",
              "0                            4                      7     0.554392   \n",
              "1                            4                      7     0.117051   \n",
              "2                            4                      7     3.093239   \n",
              "3                            4                      7     0.677797   \n",
              "4                            4                      7     0.412071   \n",
              "...                        ...                    ...          ...   \n",
              "32325                       12                      7     0.841480   \n",
              "32326                       12                      7     0.685066   \n",
              "32327                       12                      7     0.481472   \n",
              "32328                       12                      7     0.880191   \n",
              "32329                       12                      7     0.678268   \n",
              "\n",
              "       pcp_mean_lag-1  tmax_mean_lag-1  tmin_mean_lag-1  spi_mean_lag-1  \\\n",
              "0           97.103755       301.939623       292.214020        0.093447   \n",
              "1           59.292237       301.882929       288.092753        0.182926   \n",
              "2           58.196545       302.891420       289.377311        0.991663   \n",
              "3          149.210195       298.973795       287.311403        0.206751   \n",
              "4           74.556629       304.006860       290.606725       -0.075621   \n",
              "...               ...              ...              ...             ...   \n",
              "32325       25.249322       302.485864       291.402194        0.213789   \n",
              "32326       62.751591       299.755546       287.893781        0.412781   \n",
              "32327       71.453830       296.963034       286.109140        0.004455   \n",
              "32328       74.755430       297.273136       285.907031        0.847040   \n",
              "32329       25.198420       302.713732       289.277473       -0.010870   \n",
              "\n",
              "       maize_lag-2  pcp_mean_lag-2  tmax_mean_lag-2  tmin_mean_lag-2  \\\n",
              "0         0.721607      129.051864       301.518536       292.496579   \n",
              "1         0.300217       47.697564       303.988747       288.916992   \n",
              "2         4.044452       42.130629       305.494178       290.535403   \n",
              "3         0.907431      159.454723       299.404975       287.724299   \n",
              "4         0.675967       66.698670       304.644632       290.635254   \n",
              "...            ...             ...              ...              ...   \n",
              "32325     0.926596       60.841103       301.103214       290.648780   \n",
              "32326     1.038142       62.393069       299.616883       288.078306   \n",
              "32327     1.242612      129.128337       296.285672       286.086518   \n",
              "32328     0.720637       91.456254       297.102164       285.640060   \n",
              "32329     0.727710       70.263982       300.849052       288.937954   \n",
              "\n",
              "       spi_mean_lag-2  maize_lag-3  pcp_mean_lag-3  tmax_mean_lag-3  \\\n",
              "0            1.644698     0.620005      109.983325       301.786056   \n",
              "1            0.909295     0.212699       41.130026       303.298082   \n",
              "2            0.952237     2.295351       35.049776       304.824778   \n",
              "3            1.374616     0.783018      174.088260       298.908208   \n",
              "4            1.144088     0.605584       67.404588       303.930955   \n",
              "...               ...          ...             ...              ...   \n",
              "32325        0.666820     0.767325       56.355874       301.345864   \n",
              "32326       -0.008399     0.830597       89.248975       299.499617   \n",
              "32327        0.809915     0.994018      126.344999       296.054577   \n",
              "32328        1.451785     1.000904       62.046051       297.754080   \n",
              "32329        1.300713     0.598105       55.444956       301.227630   \n",
              "\n",
              "       tmin_mean_lag-3  spi_mean_lag-3  \n",
              "0           292.204097        0.514275  \n",
              "1           288.642853        0.588172  \n",
              "2           290.284886        0.371446  \n",
              "3           287.362407        0.643207  \n",
              "4           290.564185        0.553079  \n",
              "...                ...             ...  \n",
              "32325       290.478016        0.378187  \n",
              "32326       287.620716        1.717135  \n",
              "32327       285.788589        0.512137  \n",
              "32328       285.755915        0.087132  \n",
              "32329       288.821259        0.153699  \n",
              "\n",
              "[32330 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41267cf3-4df4-4b0d-b013-d9d85502af50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Countries</th>\n",
              "      <th>Sand_1</th>\n",
              "      <th>Sand_2</th>\n",
              "      <th>Sand_3</th>\n",
              "      <th>Sand_4</th>\n",
              "      <th>Sand_5</th>\n",
              "      <th>Sand_6</th>\n",
              "      <th>Sand_7</th>\n",
              "      <th>Clay_1</th>\n",
              "      <th>Clay_2</th>\n",
              "      <th>Clay_3</th>\n",
              "      <th>Clay_4</th>\n",
              "      <th>Clay_5</th>\n",
              "      <th>Clay_6</th>\n",
              "      <th>Clay_7</th>\n",
              "      <th>OC_1</th>\n",
              "      <th>OC_2</th>\n",
              "      <th>OC_3</th>\n",
              "      <th>OC_4</th>\n",
              "      <th>OC_5</th>\n",
              "      <th>OC_6</th>\n",
              "      <th>OC_7</th>\n",
              "      <th>PAW_1</th>\n",
              "      <th>PAW_2</th>\n",
              "      <th>PAW_3</th>\n",
              "      <th>PAW_4</th>\n",
              "      <th>PAW_5</th>\n",
              "      <th>PAW_6</th>\n",
              "      <th>PAW_7</th>\n",
              "      <th>Y_maize_major</th>\n",
              "      <th>Farm</th>\n",
              "      <th>Sow_Maize_month_int</th>\n",
              "      <th>Harvest_Maize_month_int</th>\n",
              "      <th>sow_to_harvest_months</th>\n",
              "      <th>maize_lag-1</th>\n",
              "      <th>pcp_mean_lag-1</th>\n",
              "      <th>tmax_mean_lag-1</th>\n",
              "      <th>tmin_mean_lag-1</th>\n",
              "      <th>spi_mean_lag-1</th>\n",
              "      <th>maize_lag-2</th>\n",
              "      <th>pcp_mean_lag-2</th>\n",
              "      <th>tmax_mean_lag-2</th>\n",
              "      <th>tmin_mean_lag-2</th>\n",
              "      <th>spi_mean_lag-2</th>\n",
              "      <th>maize_lag-3</th>\n",
              "      <th>pcp_mean_lag-3</th>\n",
              "      <th>tmax_mean_lag-3</th>\n",
              "      <th>tmin_mean_lag-3</th>\n",
              "      <th>spi_mean_lag-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007</td>\n",
              "      <td>Angola</td>\n",
              "      <td>50</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "      <td>48</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>37</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>39</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.615357</td>\n",
              "      <td>104_Angola</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.554392</td>\n",
              "      <td>97.103755</td>\n",
              "      <td>301.939623</td>\n",
              "      <td>292.214020</td>\n",
              "      <td>0.093447</td>\n",
              "      <td>0.721607</td>\n",
              "      <td>129.051864</td>\n",
              "      <td>301.518536</td>\n",
              "      <td>292.496579</td>\n",
              "      <td>1.644698</td>\n",
              "      <td>0.620005</td>\n",
              "      <td>109.983325</td>\n",
              "      <td>301.786056</td>\n",
              "      <td>292.204097</td>\n",
              "      <td>0.514275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007</td>\n",
              "      <td>Angola</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>63</td>\n",
              "      <td>59</td>\n",
              "      <td>58</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>27</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.257656</td>\n",
              "      <td>99_Angola</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.117051</td>\n",
              "      <td>59.292237</td>\n",
              "      <td>301.882929</td>\n",
              "      <td>288.092753</td>\n",
              "      <td>0.182926</td>\n",
              "      <td>0.300217</td>\n",
              "      <td>47.697564</td>\n",
              "      <td>303.988747</td>\n",
              "      <td>288.916992</td>\n",
              "      <td>0.909295</td>\n",
              "      <td>0.212699</td>\n",
              "      <td>41.130026</td>\n",
              "      <td>303.298082</td>\n",
              "      <td>288.642853</td>\n",
              "      <td>0.588172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007</td>\n",
              "      <td>Angola</td>\n",
              "      <td>69</td>\n",
              "      <td>71</td>\n",
              "      <td>70</td>\n",
              "      <td>67</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>66</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>4.286831</td>\n",
              "      <td>108_Angola</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3.093239</td>\n",
              "      <td>58.196545</td>\n",
              "      <td>302.891420</td>\n",
              "      <td>289.377311</td>\n",
              "      <td>0.991663</td>\n",
              "      <td>4.044452</td>\n",
              "      <td>42.130629</td>\n",
              "      <td>305.494178</td>\n",
              "      <td>290.535403</td>\n",
              "      <td>0.952237</td>\n",
              "      <td>2.295351</td>\n",
              "      <td>35.049776</td>\n",
              "      <td>304.824778</td>\n",
              "      <td>290.284886</td>\n",
              "      <td>0.371446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007</td>\n",
              "      <td>Angola</td>\n",
              "      <td>60</td>\n",
              "      <td>63</td>\n",
              "      <td>61</td>\n",
              "      <td>57</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.700384</td>\n",
              "      <td>102_Angola</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.677797</td>\n",
              "      <td>149.210195</td>\n",
              "      <td>298.973795</td>\n",
              "      <td>287.311403</td>\n",
              "      <td>0.206751</td>\n",
              "      <td>0.907431</td>\n",
              "      <td>159.454723</td>\n",
              "      <td>299.404975</td>\n",
              "      <td>287.724299</td>\n",
              "      <td>1.374616</td>\n",
              "      <td>0.783018</td>\n",
              "      <td>174.088260</td>\n",
              "      <td>298.908208</td>\n",
              "      <td>287.362407</td>\n",
              "      <td>0.643207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007</td>\n",
              "      <td>Angola</td>\n",
              "      <td>67</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>63</td>\n",
              "      <td>61</td>\n",
              "      <td>61</td>\n",
              "      <td>61</td>\n",
              "      <td>22</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.553450</td>\n",
              "      <td>43_Angola</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.412071</td>\n",
              "      <td>74.556629</td>\n",
              "      <td>304.006860</td>\n",
              "      <td>290.606725</td>\n",
              "      <td>-0.075621</td>\n",
              "      <td>0.675967</td>\n",
              "      <td>66.698670</td>\n",
              "      <td>304.644632</td>\n",
              "      <td>290.635254</td>\n",
              "      <td>1.144088</td>\n",
              "      <td>0.605584</td>\n",
              "      <td>67.404588</td>\n",
              "      <td>303.930955</td>\n",
              "      <td>290.564185</td>\n",
              "      <td>0.553079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32325</th>\n",
              "      <td>2016</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>73</td>\n",
              "      <td>75</td>\n",
              "      <td>74</td>\n",
              "      <td>69</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.674080</td>\n",
              "      <td>3874_Zimbabwe</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.841480</td>\n",
              "      <td>25.249322</td>\n",
              "      <td>302.485864</td>\n",
              "      <td>291.402194</td>\n",
              "      <td>0.213789</td>\n",
              "      <td>0.926596</td>\n",
              "      <td>60.841103</td>\n",
              "      <td>301.103214</td>\n",
              "      <td>290.648780</td>\n",
              "      <td>0.666820</td>\n",
              "      <td>0.767325</td>\n",
              "      <td>56.355874</td>\n",
              "      <td>301.345864</td>\n",
              "      <td>290.478016</td>\n",
              "      <td>0.378187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32326</th>\n",
              "      <td>2016</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>57</td>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>52</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.707797</td>\n",
              "      <td>3875_Zimbabwe</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.685066</td>\n",
              "      <td>62.751591</td>\n",
              "      <td>299.755546</td>\n",
              "      <td>287.893781</td>\n",
              "      <td>0.412781</td>\n",
              "      <td>1.038142</td>\n",
              "      <td>62.393069</td>\n",
              "      <td>299.616883</td>\n",
              "      <td>288.078306</td>\n",
              "      <td>-0.008399</td>\n",
              "      <td>0.830597</td>\n",
              "      <td>89.248975</td>\n",
              "      <td>299.499617</td>\n",
              "      <td>287.620716</td>\n",
              "      <td>1.717135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32327</th>\n",
              "      <td>2016</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>55</td>\n",
              "      <td>57</td>\n",
              "      <td>56</td>\n",
              "      <td>54</td>\n",
              "      <td>52</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "      <td>30</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.805844</td>\n",
              "      <td>3859_Zimbabwe</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.481472</td>\n",
              "      <td>71.453830</td>\n",
              "      <td>296.963034</td>\n",
              "      <td>286.109140</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>1.242612</td>\n",
              "      <td>129.128337</td>\n",
              "      <td>296.285672</td>\n",
              "      <td>286.086518</td>\n",
              "      <td>0.809915</td>\n",
              "      <td>0.994018</td>\n",
              "      <td>126.344999</td>\n",
              "      <td>296.054577</td>\n",
              "      <td>285.788589</td>\n",
              "      <td>0.512137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32328</th>\n",
              "      <td>2016</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>70</td>\n",
              "      <td>72</td>\n",
              "      <td>71</td>\n",
              "      <td>67</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>62</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.595883</td>\n",
              "      <td>3871_Zimbabwe</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.880191</td>\n",
              "      <td>74.755430</td>\n",
              "      <td>297.273136</td>\n",
              "      <td>285.907031</td>\n",
              "      <td>0.847040</td>\n",
              "      <td>0.720637</td>\n",
              "      <td>91.456254</td>\n",
              "      <td>297.102164</td>\n",
              "      <td>285.640060</td>\n",
              "      <td>1.451785</td>\n",
              "      <td>1.000904</td>\n",
              "      <td>62.046051</td>\n",
              "      <td>297.754080</td>\n",
              "      <td>285.755915</td>\n",
              "      <td>0.087132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32329</th>\n",
              "      <td>2016</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>63</td>\n",
              "      <td>60</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.846773</td>\n",
              "      <td>3869_Zimbabwe</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.678268</td>\n",
              "      <td>25.198420</td>\n",
              "      <td>302.713732</td>\n",
              "      <td>289.277473</td>\n",
              "      <td>-0.010870</td>\n",
              "      <td>0.727710</td>\n",
              "      <td>70.263982</td>\n",
              "      <td>300.849052</td>\n",
              "      <td>288.937954</td>\n",
              "      <td>1.300713</td>\n",
              "      <td>0.598105</td>\n",
              "      <td>55.444956</td>\n",
              "      <td>301.227630</td>\n",
              "      <td>288.821259</td>\n",
              "      <td>0.153699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32330 rows Ã— 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41267cf3-4df4-4b0d-b013-d9d85502af50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41267cf3-4df4-4b0d-b013-d9d85502af50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41267cf3-4df4-4b0d-b013-d9d85502af50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa439e79-c61a-4542-a4a5-80355ccce5ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa439e79-c61a-4542-a4a5-80355ccce5ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa439e79-c61a-4542-a4a5-80355ccce5ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8xDLHznUi7U",
        "outputId": "4c963934-7a6a-436f-8f70-1e1240399bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32330, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, `Countries` and `Farm` attributes as categorical are dropped."
      ],
      "metadata": {
        "id": "C8pog37NmvuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Countries','Farm'], axis=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "OBOm7Bu4Ui15",
        "outputId": "f3f55c91-ccc0-428e-ca67-7944527355fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Year  Sand_1  Sand_2  Sand_3  Sand_4  Sand_5  Sand_6  Sand_7  Clay_1  \\\n",
              "0      2007      50      51      51      48      45      46      46      37   \n",
              "1      2007      62      64      63      59      58      59      59      27   \n",
              "2      2007      69      71      70      67      65      65      66      19   \n",
              "3      2007      60      63      61      57      53      53      53      29   \n",
              "4      2007      67      69      68      63      61      61      61      22   \n",
              "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "32325  2016      73      75      74      69      66      66      66      20   \n",
              "32326  2016      57      58      58      54      52      51      52      28   \n",
              "32327  2016      55      57      56      54      52      51      51      30   \n",
              "32328  2016      70      72      71      67      63      63      62      17   \n",
              "32329  2016      62      64      63      60      59      60      60      24   \n",
              "\n",
              "       Clay_2  Clay_3  Clay_4  Clay_5  Clay_6  Clay_7  OC_1  OC_2  OC_3  OC_4  \\\n",
              "0          35      36      39      42      42      42  0.52  0.23  0.17  0.09   \n",
              "1          25      26      29      31      30      30  0.11  0.05  0.07  0.04   \n",
              "2          16      18      21      24      24      23  0.09  0.06  0.07  0.04   \n",
              "3          26      28      32      35      36      36  0.46  0.16  0.14  0.08   \n",
              "4          19      21      25      28      28      29  0.15  0.09  0.09  0.05   \n",
              "...       ...     ...     ...     ...     ...     ...   ...   ...   ...   ...   \n",
              "32325      18      20      24      27      27      27  0.10  0.08  0.08  0.04   \n",
              "32326      26      26      31      33      34      33  0.14  0.12  0.10  0.05   \n",
              "32327      28      30      32      34      35      35  0.53  0.41  0.30  0.22   \n",
              "32328      14      15      20      24      24      24  0.14  0.09  0.10  0.06   \n",
              "32329      22      24      27      29      28      28  0.08  0.06  0.06  0.03   \n",
              "\n",
              "       OC_5  OC_6  OC_7  PAW_1  PAW_2  PAW_3  PAW_4  PAW_5  PAW_6  PAW_7  \\\n",
              "0      0.04  0.02  0.02   0.15   0.15   0.14   0.13   0.10   0.07   0.07   \n",
              "1      0.02  0.02  0.01   0.11   0.10   0.10   0.09   0.07   0.07   0.03   \n",
              "2      0.02  0.02  0.02   0.10   0.10   0.10   0.09   0.07   0.07   0.07   \n",
              "3      0.05  0.04  0.03   0.12   0.13   0.12   0.12   0.11   0.10   0.09   \n",
              "4      0.02  0.01  0.01   0.11   0.11   0.11   0.11   0.08   0.04   0.04   \n",
              "...     ...   ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "32325  0.02  0.01  0.01   0.09   0.10   0.09   0.09   0.07   0.04   0.04   \n",
              "32326  0.03  0.01  0.01   0.13   0.14   0.13   0.11   0.09   0.03   0.03   \n",
              "32327  0.18  0.16  0.15   0.18   0.19   0.17   0.15   0.14   0.14   0.14   \n",
              "32328  0.04  0.03  0.03   0.10   0.10   0.10   0.10   0.09   0.09   0.08   \n",
              "32329  0.02  0.01  0.01   0.11   0.11   0.11   0.09   0.08   0.04   0.04   \n",
              "\n",
              "       Y_maize_major  Sow_Maize_month_int  Harvest_Maize_month_int  \\\n",
              "0           0.615357                    9                        4   \n",
              "1           0.257656                    9                        4   \n",
              "2           4.286831                    9                        4   \n",
              "3           0.700384                    9                        4   \n",
              "4           0.553450                    9                        4   \n",
              "...              ...                  ...                      ...   \n",
              "32325       0.674080                    5                       12   \n",
              "32326       0.707797                    5                       12   \n",
              "32327       0.805844                    5                       12   \n",
              "32328       0.595883                    5                       12   \n",
              "32329       0.846773                    5                       12   \n",
              "\n",
              "       sow_to_harvest_months  maize_lag-1  pcp_mean_lag-1  tmax_mean_lag-1  \\\n",
              "0                          7     0.554392       97.103755       301.939623   \n",
              "1                          7     0.117051       59.292237       301.882929   \n",
              "2                          7     3.093239       58.196545       302.891420   \n",
              "3                          7     0.677797      149.210195       298.973795   \n",
              "4                          7     0.412071       74.556629       304.006860   \n",
              "...                      ...          ...             ...              ...   \n",
              "32325                      7     0.841480       25.249322       302.485864   \n",
              "32326                      7     0.685066       62.751591       299.755546   \n",
              "32327                      7     0.481472       71.453830       296.963034   \n",
              "32328                      7     0.880191       74.755430       297.273136   \n",
              "32329                      7     0.678268       25.198420       302.713732   \n",
              "\n",
              "       tmin_mean_lag-1  spi_mean_lag-1  maize_lag-2  pcp_mean_lag-2  \\\n",
              "0           292.214020        0.093447     0.721607      129.051864   \n",
              "1           288.092753        0.182926     0.300217       47.697564   \n",
              "2           289.377311        0.991663     4.044452       42.130629   \n",
              "3           287.311403        0.206751     0.907431      159.454723   \n",
              "4           290.606725       -0.075621     0.675967       66.698670   \n",
              "...                ...             ...          ...             ...   \n",
              "32325       291.402194        0.213789     0.926596       60.841103   \n",
              "32326       287.893781        0.412781     1.038142       62.393069   \n",
              "32327       286.109140        0.004455     1.242612      129.128337   \n",
              "32328       285.907031        0.847040     0.720637       91.456254   \n",
              "32329       289.277473       -0.010870     0.727710       70.263982   \n",
              "\n",
              "       tmax_mean_lag-2  tmin_mean_lag-2  spi_mean_lag-2  maize_lag-3  \\\n",
              "0           301.518536       292.496579        1.644698     0.620005   \n",
              "1           303.988747       288.916992        0.909295     0.212699   \n",
              "2           305.494178       290.535403        0.952237     2.295351   \n",
              "3           299.404975       287.724299        1.374616     0.783018   \n",
              "4           304.644632       290.635254        1.144088     0.605584   \n",
              "...                ...              ...             ...          ...   \n",
              "32325       301.103214       290.648780        0.666820     0.767325   \n",
              "32326       299.616883       288.078306       -0.008399     0.830597   \n",
              "32327       296.285672       286.086518        0.809915     0.994018   \n",
              "32328       297.102164       285.640060        1.451785     1.000904   \n",
              "32329       300.849052       288.937954        1.300713     0.598105   \n",
              "\n",
              "       pcp_mean_lag-3  tmax_mean_lag-3  tmin_mean_lag-3  spi_mean_lag-3  \n",
              "0          109.983325       301.786056       292.204097        0.514275  \n",
              "1           41.130026       303.298082       288.642853        0.588172  \n",
              "2           35.049776       304.824778       290.284886        0.371446  \n",
              "3          174.088260       298.908208       287.362407        0.643207  \n",
              "4           67.404588       303.930955       290.564185        0.553079  \n",
              "...               ...              ...              ...             ...  \n",
              "32325       56.355874       301.345864       290.478016        0.378187  \n",
              "32326       89.248975       299.499617       287.620716        1.717135  \n",
              "32327      126.344999       296.054577       285.788589        0.512137  \n",
              "32328       62.046051       297.754080       285.755915        0.087132  \n",
              "32329       55.444956       301.227630       288.821259        0.153699  \n",
              "\n",
              "[32330 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3bf3e21-62e8-43af-956e-3636bcbffb80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Sand_1</th>\n",
              "      <th>Sand_2</th>\n",
              "      <th>Sand_3</th>\n",
              "      <th>Sand_4</th>\n",
              "      <th>Sand_5</th>\n",
              "      <th>Sand_6</th>\n",
              "      <th>Sand_7</th>\n",
              "      <th>Clay_1</th>\n",
              "      <th>Clay_2</th>\n",
              "      <th>Clay_3</th>\n",
              "      <th>Clay_4</th>\n",
              "      <th>Clay_5</th>\n",
              "      <th>Clay_6</th>\n",
              "      <th>Clay_7</th>\n",
              "      <th>OC_1</th>\n",
              "      <th>OC_2</th>\n",
              "      <th>OC_3</th>\n",
              "      <th>OC_4</th>\n",
              "      <th>OC_5</th>\n",
              "      <th>OC_6</th>\n",
              "      <th>OC_7</th>\n",
              "      <th>PAW_1</th>\n",
              "      <th>PAW_2</th>\n",
              "      <th>PAW_3</th>\n",
              "      <th>PAW_4</th>\n",
              "      <th>PAW_5</th>\n",
              "      <th>PAW_6</th>\n",
              "      <th>PAW_7</th>\n",
              "      <th>Y_maize_major</th>\n",
              "      <th>Sow_Maize_month_int</th>\n",
              "      <th>Harvest_Maize_month_int</th>\n",
              "      <th>sow_to_harvest_months</th>\n",
              "      <th>maize_lag-1</th>\n",
              "      <th>pcp_mean_lag-1</th>\n",
              "      <th>tmax_mean_lag-1</th>\n",
              "      <th>tmin_mean_lag-1</th>\n",
              "      <th>spi_mean_lag-1</th>\n",
              "      <th>maize_lag-2</th>\n",
              "      <th>pcp_mean_lag-2</th>\n",
              "      <th>tmax_mean_lag-2</th>\n",
              "      <th>tmin_mean_lag-2</th>\n",
              "      <th>spi_mean_lag-2</th>\n",
              "      <th>maize_lag-3</th>\n",
              "      <th>pcp_mean_lag-3</th>\n",
              "      <th>tmax_mean_lag-3</th>\n",
              "      <th>tmin_mean_lag-3</th>\n",
              "      <th>spi_mean_lag-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007</td>\n",
              "      <td>50</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "      <td>48</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>37</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>39</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.615357</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.554392</td>\n",
              "      <td>97.103755</td>\n",
              "      <td>301.939623</td>\n",
              "      <td>292.214020</td>\n",
              "      <td>0.093447</td>\n",
              "      <td>0.721607</td>\n",
              "      <td>129.051864</td>\n",
              "      <td>301.518536</td>\n",
              "      <td>292.496579</td>\n",
              "      <td>1.644698</td>\n",
              "      <td>0.620005</td>\n",
              "      <td>109.983325</td>\n",
              "      <td>301.786056</td>\n",
              "      <td>292.204097</td>\n",
              "      <td>0.514275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>63</td>\n",
              "      <td>59</td>\n",
              "      <td>58</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>27</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.257656</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.117051</td>\n",
              "      <td>59.292237</td>\n",
              "      <td>301.882929</td>\n",
              "      <td>288.092753</td>\n",
              "      <td>0.182926</td>\n",
              "      <td>0.300217</td>\n",
              "      <td>47.697564</td>\n",
              "      <td>303.988747</td>\n",
              "      <td>288.916992</td>\n",
              "      <td>0.909295</td>\n",
              "      <td>0.212699</td>\n",
              "      <td>41.130026</td>\n",
              "      <td>303.298082</td>\n",
              "      <td>288.642853</td>\n",
              "      <td>0.588172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007</td>\n",
              "      <td>69</td>\n",
              "      <td>71</td>\n",
              "      <td>70</td>\n",
              "      <td>67</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>66</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>4.286831</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3.093239</td>\n",
              "      <td>58.196545</td>\n",
              "      <td>302.891420</td>\n",
              "      <td>289.377311</td>\n",
              "      <td>0.991663</td>\n",
              "      <td>4.044452</td>\n",
              "      <td>42.130629</td>\n",
              "      <td>305.494178</td>\n",
              "      <td>290.535403</td>\n",
              "      <td>0.952237</td>\n",
              "      <td>2.295351</td>\n",
              "      <td>35.049776</td>\n",
              "      <td>304.824778</td>\n",
              "      <td>290.284886</td>\n",
              "      <td>0.371446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007</td>\n",
              "      <td>60</td>\n",
              "      <td>63</td>\n",
              "      <td>61</td>\n",
              "      <td>57</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.700384</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.677797</td>\n",
              "      <td>149.210195</td>\n",
              "      <td>298.973795</td>\n",
              "      <td>287.311403</td>\n",
              "      <td>0.206751</td>\n",
              "      <td>0.907431</td>\n",
              "      <td>159.454723</td>\n",
              "      <td>299.404975</td>\n",
              "      <td>287.724299</td>\n",
              "      <td>1.374616</td>\n",
              "      <td>0.783018</td>\n",
              "      <td>174.088260</td>\n",
              "      <td>298.908208</td>\n",
              "      <td>287.362407</td>\n",
              "      <td>0.643207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007</td>\n",
              "      <td>67</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>63</td>\n",
              "      <td>61</td>\n",
              "      <td>61</td>\n",
              "      <td>61</td>\n",
              "      <td>22</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.553450</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.412071</td>\n",
              "      <td>74.556629</td>\n",
              "      <td>304.006860</td>\n",
              "      <td>290.606725</td>\n",
              "      <td>-0.075621</td>\n",
              "      <td>0.675967</td>\n",
              "      <td>66.698670</td>\n",
              "      <td>304.644632</td>\n",
              "      <td>290.635254</td>\n",
              "      <td>1.144088</td>\n",
              "      <td>0.605584</td>\n",
              "      <td>67.404588</td>\n",
              "      <td>303.930955</td>\n",
              "      <td>290.564185</td>\n",
              "      <td>0.553079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32325</th>\n",
              "      <td>2016</td>\n",
              "      <td>73</td>\n",
              "      <td>75</td>\n",
              "      <td>74</td>\n",
              "      <td>69</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.674080</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.841480</td>\n",
              "      <td>25.249322</td>\n",
              "      <td>302.485864</td>\n",
              "      <td>291.402194</td>\n",
              "      <td>0.213789</td>\n",
              "      <td>0.926596</td>\n",
              "      <td>60.841103</td>\n",
              "      <td>301.103214</td>\n",
              "      <td>290.648780</td>\n",
              "      <td>0.666820</td>\n",
              "      <td>0.767325</td>\n",
              "      <td>56.355874</td>\n",
              "      <td>301.345864</td>\n",
              "      <td>290.478016</td>\n",
              "      <td>0.378187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32326</th>\n",
              "      <td>2016</td>\n",
              "      <td>57</td>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>52</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.707797</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.685066</td>\n",
              "      <td>62.751591</td>\n",
              "      <td>299.755546</td>\n",
              "      <td>287.893781</td>\n",
              "      <td>0.412781</td>\n",
              "      <td>1.038142</td>\n",
              "      <td>62.393069</td>\n",
              "      <td>299.616883</td>\n",
              "      <td>288.078306</td>\n",
              "      <td>-0.008399</td>\n",
              "      <td>0.830597</td>\n",
              "      <td>89.248975</td>\n",
              "      <td>299.499617</td>\n",
              "      <td>287.620716</td>\n",
              "      <td>1.717135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32327</th>\n",
              "      <td>2016</td>\n",
              "      <td>55</td>\n",
              "      <td>57</td>\n",
              "      <td>56</td>\n",
              "      <td>54</td>\n",
              "      <td>52</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "      <td>30</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.805844</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.481472</td>\n",
              "      <td>71.453830</td>\n",
              "      <td>296.963034</td>\n",
              "      <td>286.109140</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>1.242612</td>\n",
              "      <td>129.128337</td>\n",
              "      <td>296.285672</td>\n",
              "      <td>286.086518</td>\n",
              "      <td>0.809915</td>\n",
              "      <td>0.994018</td>\n",
              "      <td>126.344999</td>\n",
              "      <td>296.054577</td>\n",
              "      <td>285.788589</td>\n",
              "      <td>0.512137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32328</th>\n",
              "      <td>2016</td>\n",
              "      <td>70</td>\n",
              "      <td>72</td>\n",
              "      <td>71</td>\n",
              "      <td>67</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>62</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.595883</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.880191</td>\n",
              "      <td>74.755430</td>\n",
              "      <td>297.273136</td>\n",
              "      <td>285.907031</td>\n",
              "      <td>0.847040</td>\n",
              "      <td>0.720637</td>\n",
              "      <td>91.456254</td>\n",
              "      <td>297.102164</td>\n",
              "      <td>285.640060</td>\n",
              "      <td>1.451785</td>\n",
              "      <td>1.000904</td>\n",
              "      <td>62.046051</td>\n",
              "      <td>297.754080</td>\n",
              "      <td>285.755915</td>\n",
              "      <td>0.087132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32329</th>\n",
              "      <td>2016</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>63</td>\n",
              "      <td>60</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.846773</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.678268</td>\n",
              "      <td>25.198420</td>\n",
              "      <td>302.713732</td>\n",
              "      <td>289.277473</td>\n",
              "      <td>-0.010870</td>\n",
              "      <td>0.727710</td>\n",
              "      <td>70.263982</td>\n",
              "      <td>300.849052</td>\n",
              "      <td>288.937954</td>\n",
              "      <td>1.300713</td>\n",
              "      <td>0.598105</td>\n",
              "      <td>55.444956</td>\n",
              "      <td>301.227630</td>\n",
              "      <td>288.821259</td>\n",
              "      <td>0.153699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32330 rows Ã— 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3bf3e21-62e8-43af-956e-3636bcbffb80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3bf3e21-62e8-43af-956e-3636bcbffb80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3bf3e21-62e8-43af-956e-3636bcbffb80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f7ed73e-b3d1-4e02-9ff3-b4b501fe0d87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f7ed73e-b3d1-4e02-9ff3-b4b501fe0d87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f7ed73e-b3d1-4e02-9ff3-b4b501fe0d87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create train and test sets and enable subsample for faster testing."
      ],
      "metadata": {
        "id": "W8i8fCWBnLmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate a test set, the year 2016\n",
        "df_test = df[df.Year == 2016]\n",
        "df_train = df[df.Year < 2016]"
      ],
      "metadata": {
        "id": "t6t_timEUiy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsample_size_test = int(len(df_test)/10)  # subsample subset of data for faster demo\n",
        "df_test = df_test.sample(n=subsample_size_test, random_state=0)\n",
        "\n",
        "subsample_size_train = int(len(df_train)/10)\n",
        "df_train = df_train.sample(n=subsample_size_train, random_state=0)"
      ],
      "metadata": {
        "id": "WPbQ02b7VKIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape, df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phbzq4I2W4Qg",
        "outputId": "c840f646-8757-403e-d0aa-263e9ed26c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((293, 48), (2940, 48))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperopt"
      ],
      "metadata": {
        "id": "EKi--i3BprCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing hyperopt on subsample with small number of evaluations"
      ],
      "metadata": {
        "id": "ET0grpcsmHhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select regressors"
      ],
      "metadata": {
        "id": "dRj4yzzql_-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['Linear Regression', 'Random Forest', 'K-Nearest Neighbors', 'AdaBoost']\n",
        "data = {'name': names}\n",
        "df_best_regression = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "5cBBFIbBaclA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_models = [LinearRegression(), RandomForestRegressor(), KNeighborsRegressor(), AdaBoostRegressor()]"
      ],
      "metadata": {
        "id": "YHRSd6YoboCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define search spaces"
      ],
      "metadata": {
        "id": "vcuF-k7rmEIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define individual search spaces manually\n",
        "regression_search_spaces = [\n",
        "    # Linear Regression {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
        "    {\n",
        "        'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
        "        'copy_X': hp.choice('copy_X', [True, False]),\n",
        "        'n_jobs': hp.choice('n_jobs', [-1, 1, 2, 4]),  # Adjust the choices based on the available resources\n",
        "        'positive': hp.choice('positive', [True, False])\n",
        "    },\n",
        "\n",
        "    # Random Forest {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0,\n",
        "                  # 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
        "\n",
        "    {\n",
        "        'ccp_alpha': hp.uniform('ccp_alpha', 0.0, 0.5),\n",
        "        'max_depth': hp.choice('max_depth', range(1, 20)),\n",
        "        'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
        "        'n_estimators': hp.choice('n_estimators', range(50, 200, 1)),\n",
        "    },\n",
        "\n",
        "\n",
        "    # K-Nearest Neighbors {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
        "\n",
        "    {\n",
        "        'n_neighbors': hp.choice('n_neighbors', range(2, 20, 1)),\n",
        "        'p': hp.choice('p', [1, 3]),\n",
        "        'weights': hp.choice('weights', ['uniform', 'distance']),\n",
        "        'algorithm': hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
        "        'leaf_size': hp.choice('leaf_size', range(10, 40, 1)),\n",
        "    },\n",
        "\n",
        "\n",
        "    # AdaBoost {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': None}\n",
        "    {\n",
        "        'n_estimators': hp.quniform('n_estimators', 50, 200, 10),\n",
        "        'learning_rate': hp.loguniform('learning_rate', -4, 0),\n",
        "    },\n",
        "\n",
        "]\n"
      ],
      "metadata": {
        "id": "FTiYEDEjcC7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation preparation"
      ],
      "metadata": {
        "id": "Ha7l2cGrmUyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X and y\n",
        "X_train = df_train.drop(columns=['Y_maize_major','Year'], axis=1)\n",
        "y_train = df_train['Y_maize_major']\n",
        "X_test = df_test.drop(columns=['Y_maize_major','Year'], axis=1)\n",
        "y_test = df_test['Y_maize_major']\n",
        "\n",
        "# Scale to [0,1] range\n",
        "sc = MinMaxScaler()\n",
        "X_train_scaled = pd.DataFrame(sc.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(sc.transform(X_test), columns=X_test.columns)"
      ],
      "metadata": {
        "id": "0tJqxFbReHMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run hyperopt with MAE calculation"
      ],
      "metadata": {
        "id": "KPi835GUmlHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dataframe for results collection\n",
        "hpo_results = pd.DataFrame(columns=['regressor_name', 'best_cv_score', 'runtime_hpo', 'best_params', 'test_mae'])\n",
        "\n",
        "# Define the best baseline score\n",
        "best_baseline_score = 0.2161 # Define your baseline MAE score here\n",
        "\n",
        "# Define how many iterations should be done\n",
        "n_trials = 10\n",
        "\n",
        "# All individual trials will be saved here\n",
        "trials_dict = {}\n",
        "\n",
        "# Start the timer to measure the runtime of the entire pipeline\n",
        "hpo_time_start = time.time()\n",
        "\n",
        "# Run the HPO and get the best params for each classifier\n",
        "for i in range(len(df_best_regression)):\n",
        "\n",
        "    # To improve the readability of code, creating the following objects:\n",
        "    regressor_name = df_best_regression.loc[i, 'name']\n",
        "    regressor_class = regression_models[names.index(regressor_name)]  # fetch from the list not df for baseline\n",
        "    regressor_search_space = regression_search_spaces[names.index(regressor_name)]\n",
        "\n",
        "    # To improve the readability of output:\n",
        "    print()\n",
        "    print('----------------------------------------------------------------------')\n",
        "    print(f'Using *{regressor_name}* for estimation.')\n",
        "    print('----------------------------------------------------------------------')\n",
        "\n",
        "    # A objective function for receiving the CV scores for each model\n",
        "    def hyperopt_cv_score(params):\n",
        "        cv = RepeatedKFold(n_splits=5, n_repeats=5)  # can be also adjusted!\n",
        "        # Check if 'n_estimators' is in params\n",
        "        if 'n_estimators' in params:\n",
        "            # Convert 'n_estimators' to an integer\n",
        "            params['n_estimators'] = int(params['n_estimators'])\n",
        "        model = regressor_class.set_params(**params)  # use the classifier from the list\n",
        "        return cross_val_score(model,\n",
        "                               X_train_scaled, y_train,\n",
        "                               cv=cv,\n",
        "                               scoring='neg_mean_absolute_error',\n",
        "                               error_score='raise').mean()\n",
        "\n",
        "    # A helper function for finding the best model\n",
        "    def f(params):\n",
        "        global best_cv_score\n",
        "        global best_params\n",
        "        global best_time\n",
        "\n",
        "        cv_score = hyperopt_cv_score(params)\n",
        "\n",
        "        if cv_score > best_cv_score:\n",
        "            # Are we beating the best baseline score?\n",
        "            if cv_score < best_baseline_score:  # we are beating the baseline accuracy\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                print(f'*{regressor_name}* BEAT THE BASELINE of {best_baseline_score}!')\n",
        "                print(f'Better CV score: {best_cv_score}')\n",
        "                print(f'Parameter combination: {best_params}')\n",
        "                print(f'Time until beating the baseline: {best_time}s')\n",
        "            else:\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                # Print the results for reference\n",
        "                print(f'New best CV score: {best_cv_score}')\n",
        "                print(f'New best params: {best_params}')\n",
        "                print(f'Time taken until new best combination found: {round(best_time, 5)}s')\n",
        "\n",
        "        return {'loss': -cv_score,  # see the comment below\n",
        "                'status': STATUS_OK}\n",
        "        # Comment regarding 'negative cv_score' (from the referenced source):\n",
        "        ## Since we are trying to maximize the CV score (cv_score in the code above),\n",
        "        ## we must negate this value for hyperopt, since hyperopt only knows how to minimize a function.\n",
        "        ## Minimizing a function f is the same as maximizing the negative of f.\n",
        "        ## About FMIN: https://github.com/hyperopt/hyperopt/wiki/FMin\n",
        "\n",
        "    # Defining global variables to be updated\n",
        "    best_cv_score = float('-inf')  # best CV score (negative infinity since we want to maximize)\n",
        "    best_params = None  # best hyperparameter combination\n",
        "    best_time = 0  # runtime until the best CV score is computed\n",
        "    trials = Trials()  # store info at each step\n",
        "\n",
        "    # Start running the algorithm and track time\n",
        "    start_time = time.time()\n",
        "    ## Hyperopt function\n",
        "    best = fmin(f, regressor_search_space,  # use the search space associated with the classifier\n",
        "                algo=tpe.suggest,\n",
        "                max_evals=n_trials,  # how many evaluations?\n",
        "                trials=trials)\n",
        "    # Save all trials\n",
        "    trials_dict[regressor_name] = trials  # save into classifier-trials\n",
        "\n",
        "    print()\n",
        "    print('######################################################################')\n",
        "    # Print the summary of the best results\n",
        "    print(f'Best CV score in {n_trials} iterations: {best_cv_score} ({best_time}s until found).')\n",
        "\n",
        "    # Compute the accuracy score on the best model of the classifier\n",
        "    m = regressor_class.set_params(**best_params).fit(X_train_scaled, y_train) if best_params is not None else regressor_class\n",
        "    predictions = m.predict(X_test_scaled)\n",
        "    score_test = mean_absolute_error(y_test, predictions)\n",
        "    print(f'MAE on test data: {score_test}.')\n",
        "\n",
        "    # Append the best results to the df\n",
        "    hpo_results = hpo_results.append({'regressor_name': regressor_name,\n",
        "                                      'best_cv_score': best_cv_score,\n",
        "                                      'runtime_hpo': best_time,\n",
        "                                      'best_params': best_params,\n",
        "                                      'test_mae': score_test}, ignore_index=True)\n",
        "\n",
        "# Mark the end of the entire pipeline\n",
        "hpo_time_end = time.time()\n",
        "print()\n",
        "print('######################################################################')\n",
        "print(f'The duration of the entire HPO pipeline for {len(df_best_regression)} classifiers across {n_trials} trials each: ')\n",
        "print(f'{round(hpo_time_end - hpo_time_start, 5)} seconds')\n",
        "\n",
        "# Sort the model results by test MAE and then Runtime\n",
        "hpo_results = hpo_results.sort_values(['test_mae', 'runtime_hpo'], ascending=[1, 0]).reset_index(drop=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRxvgHa7kS6-",
        "outputId": "42ecb0ff-d7ea-4767-aae4-9b9783ea1d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *Linear Regression* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.24296980351822214\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': False, 'n_jobs': -1, 'positive': False}\n",
            "Time until beating the baseline: 0.4993s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.2381719753851962\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': True, 'n_jobs': -1, 'positive': True}\n",
            "Time until beating the baseline: 2.1371s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.23794360018664318\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'positive': True}\n",
            "Time until beating the baseline: 4.9545s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47trial/s, best loss: 0.23794360018664318]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.23794360018664318 (4.9545s until found).\n",
            "MAE on test data: 0.1829332075688155.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *Random Forest* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-7168c77f01a7>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*Random Forest* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.5689560338431129\n",
            "Parameter combination: {'ccp_alpha': 0.17568997182691004, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 166}\n",
            "Time until beating the baseline: 15.4454s\n",
            "*Random Forest* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.4465440553777596\n",
            "Parameter combination: {'ccp_alpha': 0.06613672666764309, 'max_depth': 19, 'max_features': 'log2', 'n_estimators': 118}\n",
            "Time until beating the baseline: 86.9503s\n",
            "*Random Forest* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.30201715068763396\n",
            "Parameter combination: {'ccp_alpha': 0.005425925728565151, 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 194}\n",
            "Time until beating the baseline: 242.6732s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [04:37<00:00, 27.76s/trial, best loss: 0.30201715068763396]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.30201715068763396 (242.6732s until found).\n",
            "MAE on test data: 0.22342803514806342.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *K-Nearest Neighbors* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-7168c77f01a7>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*K-Nearest Neighbors* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.42496297725946097\n",
            "Parameter combination: {'algorithm': 'auto', 'leaf_size': 27, 'n_neighbors': 13, 'p': 1, 'weights': 'uniform'}\n",
            "Time until beating the baseline: 2.6802s\n",
            "*K-Nearest Neighbors* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.4028675948951836\n",
            "Parameter combination: {'algorithm': 'brute', 'leaf_size': 26, 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
            "Time until beating the baseline: 6.6468s\n",
            "*K-Nearest Neighbors* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.40070927168712017\n",
            "Parameter combination: {'algorithm': 'kd_tree', 'leaf_size': 28, 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
            "Time until beating the baseline: 9.5589s\n",
            "*K-Nearest Neighbors* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.38299779346796575\n",
            "Parameter combination: {'algorithm': 'brute', 'leaf_size': 32, 'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n",
            "Time until beating the baseline: 54.8343s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:21<00:00, 14.17s/trial, best loss: 0.38299779346796575]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.38299779346796575 (54.8343s until found).\n",
            "MAE on test data: 0.2810844086893468.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *AdaBoost* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-7168c77f01a7>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*AdaBoost* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.29367602226851725\n",
            "Parameter combination: {'learning_rate': 0.033608926527254404, 'n_estimators': 160}\n",
            "Time until beating the baseline: 87.0017s\n",
            "*AdaBoost* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.2931456899903173\n",
            "Parameter combination: {'learning_rate': 0.09217094503368232, 'n_estimators': 110}\n",
            "Time until beating the baseline: 619.6593s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [10:19<00:00, 61.97s/trial, best loss: 0.2931456899903173]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.2931456899903173 (619.6593s until found).\n",
            "MAE on test data: 0.24396658069163268.\n",
            "\n",
            "######################################################################\n",
            "The duration of the entire HPO pipeline for 4 classifiers across 10 trials each: \n",
            "1050.94073 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-7168c77f01a7>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column which says if the classifier beat the baseline\n",
        "hpo_results['beats_bl'] = np.where(hpo_results.loc[:,'test_mae'] < best_baseline_score, 'yes', 'no')\n",
        "hpo_results.to_csv('hpo_results_mae.csv', index=False)\n",
        "# See the HPO results\n",
        "hpo_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "pt0V7-FgkS4a",
        "outputId": "3fb41cbc-6552-45ad-dcf8-ac68fa3e57aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        regressor_name  best_cv_score  runtime_hpo  \\\n",
              "0    Linear Regression      -0.237944       4.9545   \n",
              "1        Random Forest      -0.302017     242.6732   \n",
              "2             AdaBoost      -0.293146     619.6593   \n",
              "3  K-Nearest Neighbors      -0.382998      54.8343   \n",
              "\n",
              "                                         best_params  test_mae beats_bl  \n",
              "0  {'copy_X': True, 'fit_intercept': True, 'n_job...  0.182933      yes  \n",
              "1  {'ccp_alpha': 0.005425925728565151, 'max_depth...  0.223428       no  \n",
              "2  {'learning_rate': 0.09217094503368232, 'n_esti...  0.243967       no  \n",
              "3  {'algorithm': 'brute', 'leaf_size': 32, 'n_nei...  0.281084       no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ba2274a-14e9-4003-be4e-37dfa54d6743\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>regressor_name</th>\n",
              "      <th>best_cv_score</th>\n",
              "      <th>runtime_hpo</th>\n",
              "      <th>best_params</th>\n",
              "      <th>test_mae</th>\n",
              "      <th>beats_bl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>-0.237944</td>\n",
              "      <td>4.9545</td>\n",
              "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
              "      <td>0.182933</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>-0.302017</td>\n",
              "      <td>242.6732</td>\n",
              "      <td>{'ccp_alpha': 0.005425925728565151, 'max_depth...</td>\n",
              "      <td>0.223428</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>-0.293146</td>\n",
              "      <td>619.6593</td>\n",
              "      <td>{'learning_rate': 0.09217094503368232, 'n_esti...</td>\n",
              "      <td>0.243967</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>K-Nearest Neighbors</td>\n",
              "      <td>-0.382998</td>\n",
              "      <td>54.8343</td>\n",
              "      <td>{'algorithm': 'brute', 'leaf_size': 32, 'n_nei...</td>\n",
              "      <td>0.281084</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ba2274a-14e9-4003-be4e-37dfa54d6743')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ba2274a-14e9-4003-be4e-37dfa54d6743 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ba2274a-14e9-4003-be4e-37dfa54d6743');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc5b8faa-7be4-4902-bcba-ae6fa8c6c315\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc5b8faa-7be4-4902-bcba-ae6fa8c6c315')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc5b8faa-7be4-4902-bcba-ae6fa8c6c315 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run hyperopt with RMSE calculation"
      ],
      "metadata": {
        "id": "4VcuJAJAmuAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dataframe for results collection\n",
        "hpo_results = pd.DataFrame(columns=['regressor_name', 'best_cv_score', 'runtime_hpo', 'best_params', 'test_rmse'])\n",
        "\n",
        "# Define the best baseline score\n",
        "best_baseline_score = 0.3288  # Define your baseline RMSE score here\n",
        "\n",
        "# Define how many iterations should be done\n",
        "n_trials = 10\n",
        "\n",
        "# All individual trials will be saved here\n",
        "trials_dict = {}\n",
        "\n",
        "# Start the timer to measure the runtime of the entire pipeline\n",
        "hpo_time_start = time.time()\n",
        "\n",
        "# Run the HPO and get the best params for each classifier\n",
        "for i in range(len(df_best_regression)):\n",
        "\n",
        "    # To improve the readability of code, creating the following objects:\n",
        "    regressor_name = df_best_regression.loc[i, 'name']\n",
        "    regressor_class = regression_models[names.index(regressor_name)]  # fetch from the list not df for baseline\n",
        "    regressor_search_space = regression_search_spaces[names.index(regressor_name)]\n",
        "\n",
        "    # To improve the readability of output:\n",
        "    print()\n",
        "    print('----------------------------------------------------------------------')\n",
        "    print(f'Using *{regressor_name}* for estimation.')\n",
        "    print('----------------------------------------------------------------------')\n",
        "\n",
        "    # A objective function for receiving the CV scores for each model\n",
        "    def hyperopt_cv_score(params):\n",
        "        cv = RepeatedKFold(n_splits=5, n_repeats=5)  # can be also adjusted!\n",
        "        # Check if 'n_estimators' is in params\n",
        "        if 'n_estimators' in params:\n",
        "            # Convert 'n_estimators' to an integer\n",
        "            params['n_estimators'] = int(params['n_estimators'])\n",
        "        model = regressor_class.set_params(**params)  # use the classifier from the list\n",
        "        return cross_val_score(model,\n",
        "                               X_train_scaled, y_train,\n",
        "                               cv=cv,\n",
        "                               scoring='neg_root_mean_squared_error',\n",
        "                               error_score='raise').mean()\n",
        "\n",
        "    # A helper function for finding the best model\n",
        "    def f(params):\n",
        "        global best_cv_score\n",
        "        global best_params\n",
        "        global best_time\n",
        "\n",
        "        cv_score = hyperopt_cv_score(params)\n",
        "\n",
        "        if cv_score > best_cv_score:\n",
        "            # Are we beating the best baseline score?\n",
        "            if cv_score < best_baseline_score:  # we are beating the baseline accuracy\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                print(f'*{regressor_name}* BEAT THE BASELINE of {best_baseline_score}!')\n",
        "                print(f'Better CV score: {best_cv_score}')\n",
        "                print(f'Parameter combination: {best_params}')\n",
        "                print(f'Time until beating the baseline: {best_time}s')\n",
        "            else:\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                # Print the results for reference\n",
        "                print(f'New best CV score: {best_cv_score}')\n",
        "                print(f'New best params: {best_params}')\n",
        "                print(f'Time taken until new best combination found: {round(best_time, 5)}s')\n",
        "\n",
        "        return {'loss': -cv_score,  # see the comment below\n",
        "                'status': STATUS_OK}\n",
        "        # Comment regarding 'negative cv_score' (from the referenced source):\n",
        "        ## Since we are trying to maximize the CV score (cv_score in the code above),\n",
        "        ## we must negate this value for hyperopt, since hyperopt only knows how to minimize a function.\n",
        "        ## Minimizing a function f is the same as maximizing the negative of f.\n",
        "        ## About FMIN: https://github.com/hyperopt/hyperopt/wiki/FMin\n",
        "\n",
        "    # Defining global variables to be updated\n",
        "    best_cv_score = float('-inf')  # best CV score (negative infinity since we want to maximize)\n",
        "    best_params = None  # best hyperparameter combination\n",
        "    best_time = 0  # runtime until the best CV score is computed\n",
        "    trials = Trials()  # store info at each step\n",
        "\n",
        "    # Start running the algorithm and track time\n",
        "    start_time = time.time()\n",
        "    ## Hyperopt function\n",
        "    best = fmin(f, regressor_search_space,  # use the search space associated with the classifier\n",
        "                algo=tpe.suggest,\n",
        "                max_evals=n_trials,  # how many evaluations?\n",
        "                trials=trials)\n",
        "    # Save all trials\n",
        "    trials_dict[regressor_name] = trials  # save into classifier-trials\n",
        "\n",
        "    print()\n",
        "    print('######################################################################')\n",
        "    # Print the summary of the best results\n",
        "    print(f'Best CV score in {n_trials} iterations: {best_cv_score} ({best_time}s until found).')\n",
        "\n",
        "    # Compute the accuracy score on the best model of the classifier\n",
        "    m = regressor_class.set_params(**best_params).fit(X_train_scaled, y_train) if best_params is not None else regressor_class\n",
        "    predictions = m.predict(X_test_scaled)\n",
        "    score_test = mean_squared_error(y_test, predictions, squared=False)  # RMSE calculation\n",
        "    print(f'RMSE on test data: {score_test}.')\n",
        "\n",
        "    # Append the best results to the df\n",
        "    hpo_results = hpo_results.append({'regressor_name': regressor_name,\n",
        "                                      'best_cv_score': best_cv_score,\n",
        "                                      'runtime_hpo': best_time,\n",
        "                                      'best_params': best_params,\n",
        "                                      'test_rmse': score_test}, ignore_index=True)\n",
        "\n",
        "# Mark the end of the entire pipeline\n",
        "hpo_time_end = time.time()\n",
        "print()\n",
        "print('######################################################################')\n",
        "print(f'The duration of the entire HPO pipeline for {len(df_best_regression)} classifiers across {n_trials} trials each: ')\n",
        "print(f'{round(hpo_time_end - hpo_time_start, 5)} seconds')\n",
        "\n",
        "# Sort the model results by test RMSE and then Runtime\n",
        "hpo_results = hpo_results.sort_values(['test_rmse', 'runtime_hpo'], ascending=[1, 0]).reset_index(drop=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgWVObG9kSy-",
        "outputId": "0e92c291-278d-4cac-81f2-90ea52edf69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *Linear Regression* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.3868316894469164\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': True, 'n_jobs': 4, 'positive': True}\n",
            "Time until beating the baseline: 0.4168s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.38192039781586506\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': True, 'n_jobs': 4, 'positive': False}\n",
            "Time until beating the baseline: 1.4502s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.3805624690688404\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': True, 'n_jobs': 4, 'positive': False}\n",
            "Time until beating the baseline: 2.4097s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.12trial/s, best loss: 0.3805624690688404]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.3805624690688404 (2.4097s until found).\n",
            "RMSE on test data: 0.2949361891809478.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *Random Forest* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-5841f11c98ab>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*Random Forest* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.6375666295322734\n",
            "Parameter combination: {'ccp_alpha': 0.04277491500367392, 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 97}\n",
            "Time until beating the baseline: 19.2097s\n",
            "*Random Forest* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.5325815779130417\n",
            "Parameter combination: {'ccp_alpha': 0.017833706147461714, 'max_depth': 14, 'max_features': 'sqrt', 'n_estimators': 73}\n",
            "Time until beating the baseline: 58.9603s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [05:01<00:00, 30.16s/trial, best loss: 0.5325815779130417]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.5325815779130417 (58.9603s until found).\n",
            "RMSE on test data: 1.5383144632229695.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *K-Nearest Neighbors* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-5841f11c98ab>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*K-Nearest Neighbors* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.6039470445604822\n",
            "Parameter combination: {'algorithm': 'ball_tree', 'leaf_size': 19, 'n_neighbors': 9, 'p': 3, 'weights': 'distance'}\n",
            "Time until beating the baseline: 42.1226s\n",
            "*K-Nearest Neighbors* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.5910855238751407\n",
            "Parameter combination: {'algorithm': 'kd_tree', 'leaf_size': 22, 'n_neighbors': 4, 'p': 3, 'weights': 'distance'}\n",
            "Time until beating the baseline: 56.1241s\n",
            "*K-Nearest Neighbors* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.5851321055789337\n",
            "Parameter combination: {'algorithm': 'ball_tree', 'leaf_size': 31, 'n_neighbors': 5, 'p': 3, 'weights': 'distance'}\n",
            "Time until beating the baseline: 182.0509s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [03:10<00:00, 19.10s/trial, best loss: 0.5851321055789337]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.5851321055789337 (182.0509s until found).\n",
            "RMSE on test data: 1.18047450780439.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *AdaBoost* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-5841f11c98ab>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*AdaBoost* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.4654391461685109\n",
            "Parameter combination: {'learning_rate': 0.4391853838567028, 'n_estimators': 70}\n",
            "Time until beating the baseline: 27.8457s\n",
            "*AdaBoost* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.4516744138694081\n",
            "Parameter combination: {'learning_rate': 0.03820226790591132, 'n_estimators': 80}\n",
            "Time until beating the baseline: 162.6616s\n",
            "*AdaBoost* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.4483900775828862\n",
            "Parameter combination: {'learning_rate': 0.03580302378682828, 'n_estimators': 120}\n",
            "Time until beating the baseline: 275.2787s\n",
            "*AdaBoost* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.4463879026121158\n",
            "Parameter combination: {'learning_rate': 0.040566558900453256, 'n_estimators': 130}\n",
            "Time until beating the baseline: 345.8561s\n",
            "*AdaBoost* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.44297855994739466\n",
            "Parameter combination: {'learning_rate': 0.16333272051917694, 'n_estimators': 60}\n",
            "Time until beating the baseline: 378.6038s\n",
            "*AdaBoost* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.4424508597968975\n",
            "Parameter combination: {'learning_rate': 0.06406448823848802, 'n_estimators': 190}\n",
            "Time until beating the baseline: 529.2484s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [08:49<00:00, 52.93s/trial, best loss: 0.4424508597968975]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 10 iterations: -0.4424508597968975 (529.2484s until found).\n",
            "RMSE on test data: 1.826196318963006.\n",
            "\n",
            "######################################################################\n",
            "The duration of the entire HPO pipeline for 4 classifiers across 10 trials each: \n",
            "1034.06947 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-5841f11c98ab>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column which says if the classifier beat the baseline\n",
        "hpo_results['beats_bl'] = np.where(hpo_results.loc[:,'test_rmse'] < best_baseline_score, 'yes', 'no')\n",
        "hpo_results.to_csv('hpo_results_rmse.csv', index=False)\n",
        "# See the HPO results\n",
        "hpo_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "vBhFqCfYkSw0",
        "outputId": "5b09622a-fc23-4a36-d466-25413f4560a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        regressor_name  best_cv_score  runtime_hpo  \\\n",
              "0    Linear Regression      -0.380562       2.4097   \n",
              "1  K-Nearest Neighbors      -0.585132     182.0509   \n",
              "2        Random Forest      -0.532582      58.9603   \n",
              "3             AdaBoost      -0.442451     529.2484   \n",
              "\n",
              "                                         best_params  test_rmse beats_bl  \n",
              "0  {'copy_X': False, 'fit_intercept': True, 'n_jo...   0.294936      yes  \n",
              "1  {'algorithm': 'ball_tree', 'leaf_size': 31, 'n...   1.180475       no  \n",
              "2  {'ccp_alpha': 0.017833706147461714, 'max_depth...   1.538314       no  \n",
              "3  {'learning_rate': 0.06406448823848802, 'n_esti...   1.826196       no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-558468d8-e5b6-4cd4-84df-ca4d5504eea8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>regressor_name</th>\n",
              "      <th>best_cv_score</th>\n",
              "      <th>runtime_hpo</th>\n",
              "      <th>best_params</th>\n",
              "      <th>test_rmse</th>\n",
              "      <th>beats_bl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>-0.380562</td>\n",
              "      <td>2.4097</td>\n",
              "      <td>{'copy_X': False, 'fit_intercept': True, 'n_jo...</td>\n",
              "      <td>0.294936</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>K-Nearest Neighbors</td>\n",
              "      <td>-0.585132</td>\n",
              "      <td>182.0509</td>\n",
              "      <td>{'algorithm': 'ball_tree', 'leaf_size': 31, 'n...</td>\n",
              "      <td>1.180475</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>-0.532582</td>\n",
              "      <td>58.9603</td>\n",
              "      <td>{'ccp_alpha': 0.017833706147461714, 'max_depth...</td>\n",
              "      <td>1.538314</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>-0.442451</td>\n",
              "      <td>529.2484</td>\n",
              "      <td>{'learning_rate': 0.06406448823848802, 'n_esti...</td>\n",
              "      <td>1.826196</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-558468d8-e5b6-4cd4-84df-ca4d5504eea8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-558468d8-e5b6-4cd4-84df-ca4d5504eea8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-558468d8-e5b6-4cd4-84df-ca4d5504eea8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1068e9c2-df36-4d68-a6ae-926e538ca078\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1068e9c2-df36-4d68-a6ae-926e538ca078')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1068e9c2-df36-4d68-a6ae-926e538ca078 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing hyperopt with Linear Regression for full dataset"
      ],
      "metadata": {
        "id": "AFGGbfGQm5Qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload the full dataset and prepare for modelling"
      ],
      "metadata": {
        "id": "XOfrz8THnZ45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('df_prepped.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfqq4M2HnCXm",
        "outputId": "b6a4acbe-16fe-46dd-ff8e-21a7e0254383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32330, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Countries','Farm'], axis=1)"
      ],
      "metadata": {
        "id": "VHGlhR3unCVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df[df.Year == 2016]\n",
        "df_train = df[df.Year < 2016]"
      ],
      "metadata": {
        "id": "whcOC-j_nCR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X and y\n",
        "X_train = df_train.drop(columns=['Y_maize_major','Year'], axis=1)\n",
        "y_train = df_train['Y_maize_major']\n",
        "X_test = df_test.drop(columns=['Y_maize_major','Year'], axis=1)\n",
        "y_test = df_test['Y_maize_major']\n",
        "\n",
        "# Scale to [0,1] range\n",
        "sc = MinMaxScaler()\n",
        "X_train_scaled = pd.DataFrame(sc.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(sc.transform(X_test), columns=X_test.columns)"
      ],
      "metadata": {
        "id": "Suh_-oQWnCPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['Linear Regression']\n",
        "data = {'name': names}\n",
        "df_best_regression = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "0d-tAYUakSm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run hyperopt with MAE"
      ],
      "metadata": {
        "id": "g9LiLcpSno2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dataframe for results collection\n",
        "hpo_results = pd.DataFrame(columns=['regressor_name', 'best_cv_score', 'runtime_hpo', 'best_params', 'test_mae'])\n",
        "\n",
        "# Define the best baseline score\n",
        "best_baseline_score = 0.2161 # Define your baseline MAE score here\n",
        "\n",
        "# Define how many iterations should be done\n",
        "n_trials = 200\n",
        "\n",
        "# All individual trials will be saved here\n",
        "trials_dict = {}\n",
        "\n",
        "# Start the timer to measure the runtime of the entire pipeline\n",
        "hpo_time_start = time.time()\n",
        "\n",
        "# Run the HPO and get the best params for each classifier\n",
        "for i in range(len(df_best_regression)):\n",
        "\n",
        "    # To improve the readability of code, creating the following objects:\n",
        "    regressor_name = df_best_regression.loc[i, 'name']\n",
        "    regressor_class = regression_models[names.index(regressor_name)]  # fetch from the list not df for baseline\n",
        "    regressor_search_space = regression_search_spaces[names.index(regressor_name)]\n",
        "\n",
        "    # To improve the readability of output:\n",
        "    print()\n",
        "    print('----------------------------------------------------------------------')\n",
        "    print(f'Using *{regressor_name}* for estimation.')\n",
        "    print('----------------------------------------------------------------------')\n",
        "\n",
        "    # A objective function for receiving the CV scores for each model\n",
        "    def hyperopt_cv_score(params):\n",
        "        cv = RepeatedKFold(n_splits=5, n_repeats=5)  # can be also adjusted!\n",
        "        # Check if 'n_estimators' is in params\n",
        "        if 'n_estimators' in params:\n",
        "            # Convert 'n_estimators' to an integer\n",
        "            params['n_estimators'] = int(params['n_estimators'])\n",
        "        model = regressor_class.set_params(**params)  # use the classifier from the list\n",
        "        return cross_val_score(model,\n",
        "                               X_train_scaled, y_train,\n",
        "                               cv=cv,\n",
        "                               scoring='neg_mean_absolute_error',\n",
        "                               error_score='raise').mean()\n",
        "\n",
        "    # A helper function for finding the best model\n",
        "    def f(params):\n",
        "        global best_cv_score\n",
        "        global best_params\n",
        "        global best_time\n",
        "\n",
        "        cv_score = hyperopt_cv_score(params)\n",
        "\n",
        "        if cv_score > best_cv_score:\n",
        "            # Are we beating the best baseline score?\n",
        "            if cv_score < best_baseline_score:  # we are beating the baseline accuracy\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                print(f'*{regressor_name}* BEAT THE BASELINE of {best_baseline_score}!')\n",
        "                print(f'Better CV score: {best_cv_score}')\n",
        "                print(f'Parameter combination: {best_params}')\n",
        "                print(f'Time until beating the baseline: {best_time}s')\n",
        "            else:\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                # Print the results for reference\n",
        "                print(f'New best CV score: {best_cv_score}')\n",
        "                print(f'New best params: {best_params}')\n",
        "                print(f'Time taken until new best combination found: {round(best_time, 5)}s')\n",
        "\n",
        "        return {'loss': -cv_score,  # see the comment below\n",
        "                'status': STATUS_OK}\n",
        "        # Comment regarding 'negative cv_score' (from the referenced source):\n",
        "        ## Since we are trying to maximize the CV score (cv_score in the code above),\n",
        "        ## we must negate this value for hyperopt, since hyperopt only knows how to minimize a function.\n",
        "        ## Minimizing a function f is the same as maximizing the negative of f.\n",
        "        ## About FMIN: https://github.com/hyperopt/hyperopt/wiki/FMin\n",
        "\n",
        "    # Defining global variables to be updated\n",
        "    best_cv_score = float('-inf')  # best CV score (negative infinity since we want to maximize)\n",
        "    best_params = None  # best hyperparameter combination\n",
        "    best_time = 0  # runtime until the best CV score is computed\n",
        "    trials = Trials()  # store info at each step\n",
        "\n",
        "    # Start running the algorithm and track time\n",
        "    start_time = time.time()\n",
        "    ## Hyperopt function\n",
        "    best = fmin(f, regressor_search_space,  # use the search space associated with the classifier\n",
        "                algo=tpe.suggest,\n",
        "                max_evals=n_trials,  # how many evaluations?\n",
        "                trials=trials)\n",
        "    # Save all trials\n",
        "    trials_dict[regressor_name] = trials  # save into classifier-trials\n",
        "\n",
        "    print()\n",
        "    print('######################################################################')\n",
        "    # Print the summary of the best results\n",
        "    print(f'Best CV score in {n_trials} iterations: {best_cv_score} ({best_time}s until found).')\n",
        "\n",
        "    # Compute the accuracy score on the best model of the classifier\n",
        "    m = regressor_class.set_params(**best_params).fit(X_train_scaled, y_train) if best_params is not None else regressor_class\n",
        "    predictions = m.predict(X_test_scaled)\n",
        "    score_test = mean_absolute_error(y_test, predictions)\n",
        "    print(f'MAE on test data: {score_test}.')\n",
        "\n",
        "    # Append the best results to the df\n",
        "    hpo_results = hpo_results.append({'regressor_name': regressor_name,\n",
        "                                      'best_cv_score': best_cv_score,\n",
        "                                      'runtime_hpo': best_time,\n",
        "                                      'best_params': best_params,\n",
        "                                      'test_mae': score_test}, ignore_index=True)\n",
        "\n",
        "# Mark the end of the entire pipeline\n",
        "hpo_time_end = time.time()\n",
        "print()\n",
        "print('######################################################################')\n",
        "print(f'The duration of the entire HPO pipeline for {len(df_best_regression)} classifiers across {n_trials} trials each: ')\n",
        "print(f'{round(hpo_time_end - hpo_time_start, 5)} seconds')\n",
        "\n",
        "# Sort the model results by test MAE and then Runtime\n",
        "hpo_results = hpo_results.sort_values(['test_mae', 'runtime_hpo'], ascending=[1, 0]).reset_index(drop=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2uuMLKwkSkE",
        "outputId": "366d3472-b397-43ec-8054-d0f3e3b010a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *Linear Regression* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.23054177608914553\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': True, 'n_jobs': 2, 'positive': False}\n",
            "Time until beating the baseline: 2.9925s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.2303309940471637\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': False, 'n_jobs': 2, 'positive': False}\n",
            "Time until beating the baseline: 9.5755s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.2288610280079438\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': True, 'n_jobs': 2, 'positive': True}\n",
            "Time until beating the baseline: 15.1442s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.22883618191451102\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': True, 'n_jobs': 2, 'positive': True}\n",
            "Time until beating the baseline: 35.699s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.2288258698423981\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': True, 'n_jobs': 2, 'positive': True}\n",
            "Time until beating the baseline: 84.6134s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.22881260902783138\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': True, 'n_jobs': 2, 'positive': True}\n",
            "Time until beating the baseline: 169.494s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.2161!\n",
            "Better CV score: -0.22880630895136356\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': True, 'n_jobs': 2, 'positive': True}\n",
            "Time until beating the baseline: 269.525s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [09:35<00:00,  2.88s/trial, best loss: 0.22880630895136356]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 200 iterations: -0.22880630895136356 (269.525s until found).\n",
            "MAE on test data: 0.19942829240564214.\n",
            "\n",
            "######################################################################\n",
            "The duration of the entire HPO pipeline for 1 classifiers across 200 trials each: \n",
            "575.53051 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-d02575bd6893>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column which says if the classifier beat the baseline\n",
        "hpo_results['beats_bl'] = np.where(hpo_results.loc[:,'test_mae'] < best_baseline_score, 'yes', 'no')\n",
        "hpo_results.to_csv('hpo_results_mae_lr.csv', index=False)\n",
        "# See the HPO results\n",
        "hpo_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Zz7J4F0bkShR",
        "outputId": "49bd71f2-51d3-4ccf-d2f2-bc6e0f6a5256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      regressor_name  best_cv_score  runtime_hpo  \\\n",
              "0  Linear Regression      -0.228806      269.525   \n",
              "\n",
              "                                         best_params  test_mae beats_bl  \n",
              "0  {'copy_X': True, 'fit_intercept': True, 'n_job...  0.199428      yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01bdc658-d1a1-4cb1-9d4a-5c012df8d0b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>regressor_name</th>\n",
              "      <th>best_cv_score</th>\n",
              "      <th>runtime_hpo</th>\n",
              "      <th>best_params</th>\n",
              "      <th>test_mae</th>\n",
              "      <th>beats_bl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>-0.228806</td>\n",
              "      <td>269.525</td>\n",
              "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
              "      <td>0.199428</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01bdc658-d1a1-4cb1-9d4a-5c012df8d0b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01bdc658-d1a1-4cb1-9d4a-5c012df8d0b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01bdc658-d1a1-4cb1-9d4a-5c012df8d0b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run hyperopt with RMSE"
      ],
      "metadata": {
        "id": "TMmzIAJ7nv9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dataframe for results collection\n",
        "hpo_results = pd.DataFrame(columns=['regressor_name', 'best_cv_score', 'runtime_hpo', 'best_params', 'test_rmse'])\n",
        "\n",
        "# Define the best baseline score\n",
        "best_baseline_score = 0.3288  # Define your baseline RMSE score here\n",
        "\n",
        "# Define how many iterations should be done\n",
        "n_trials = 200\n",
        "\n",
        "# All individual trials will be saved here\n",
        "trials_dict = {}\n",
        "\n",
        "# Start the timer to measure the runtime of the entire pipeline\n",
        "hpo_time_start = time.time()\n",
        "\n",
        "# Run the HPO and get the best params for each classifier\n",
        "for i in range(len(df_best_regression)):\n",
        "\n",
        "    # To improve the readability of code, creating the following objects:\n",
        "    regressor_name = df_best_regression.loc[i, 'name']\n",
        "    regressor_class = regression_models[names.index(regressor_name)]  # fetch from the list not df for baseline\n",
        "    regressor_search_space = regression_search_spaces[names.index(regressor_name)]\n",
        "\n",
        "    # To improve the readability of output:\n",
        "    print()\n",
        "    print('----------------------------------------------------------------------')\n",
        "    print(f'Using *{regressor_name}* for estimation.')\n",
        "    print('----------------------------------------------------------------------')\n",
        "\n",
        "    # A objective function for receiving the CV scores for each model\n",
        "    def hyperopt_cv_score(params):\n",
        "        cv = RepeatedKFold(n_splits=5, n_repeats=5)  # can be also adjusted!\n",
        "        # Check if 'n_estimators' is in params\n",
        "        if 'n_estimators' in params:\n",
        "            # Convert 'n_estimators' to an integer\n",
        "            params['n_estimators'] = int(params['n_estimators'])\n",
        "        model = regressor_class.set_params(**params)  # use the classifier from the list\n",
        "        return cross_val_score(model,\n",
        "                               X_train_scaled, y_train,\n",
        "                               cv=cv,\n",
        "                               scoring='neg_root_mean_squared_error',\n",
        "                               error_score='raise').mean()\n",
        "\n",
        "    # A helper function for finding the best model\n",
        "    def f(params):\n",
        "        global best_cv_score\n",
        "        global best_params\n",
        "        global best_time\n",
        "\n",
        "        cv_score = hyperopt_cv_score(params)\n",
        "\n",
        "        if cv_score > best_cv_score:\n",
        "            # Are we beating the best baseline score?\n",
        "            if cv_score < best_baseline_score:  # we are beating the baseline accuracy\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                print(f'*{regressor_name}* BEAT THE BASELINE of {best_baseline_score}!')\n",
        "                print(f'Better CV score: {best_cv_score}')\n",
        "                print(f'Parameter combination: {best_params}')\n",
        "                print(f'Time until beating the baseline: {best_time}s')\n",
        "            else:\n",
        "                best_cv_score = cv_score  # what is the best score?\n",
        "                best_params = params  # what are the best params?\n",
        "                best_time = round(time.time() - start_time, 4)  # track how much time it took to find the best params\n",
        "\n",
        "                # Print the results for reference\n",
        "                print(f'New best CV score: {best_cv_score}')\n",
        "                print(f'New best params: {best_params}')\n",
        "                print(f'Time taken until new best combination found: {round(best_time, 5)}s')\n",
        "\n",
        "        return {'loss': -cv_score,  # see the comment below\n",
        "                'status': STATUS_OK}\n",
        "        # Comment regarding 'negative cv_score' (from the referenced source):\n",
        "        ## Since we are trying to maximize the CV score (cv_score in the code above),\n",
        "        ## we must negate this value for hyperopt, since hyperopt only knows how to minimize a function.\n",
        "        ## Minimizing a function f is the same as maximizing the negative of f.\n",
        "        ## About FMIN: https://github.com/hyperopt/hyperopt/wiki/FMin\n",
        "\n",
        "    # Defining global variables to be updated\n",
        "    best_cv_score = float('-inf')  # best CV score (negative infinity since we want to maximize)\n",
        "    best_params = None  # best hyperparameter combination\n",
        "    best_time = 0  # runtime until the best CV score is computed\n",
        "    trials = Trials()  # store info at each step\n",
        "\n",
        "    # Start running the algorithm and track time\n",
        "    start_time = time.time()\n",
        "    ## Hyperopt function\n",
        "    best = fmin(f, regressor_search_space,  # use the search space associated with the classifier\n",
        "                algo=tpe.suggest,\n",
        "                max_evals=n_trials,  # how many evaluations?\n",
        "                trials=trials)\n",
        "    # Save all trials\n",
        "    trials_dict[regressor_name] = trials  # save into classifier-trials\n",
        "\n",
        "    print()\n",
        "    print('######################################################################')\n",
        "    # Print the summary of the best results\n",
        "    print(f'Best CV score in {n_trials} iterations: {best_cv_score} ({best_time}s until found).')\n",
        "\n",
        "    # Compute the accuracy score on the best model of the classifier\n",
        "    m = regressor_class.set_params(**best_params).fit(X_train_scaled, y_train) if best_params is not None else regressor_class\n",
        "    predictions = m.predict(X_test_scaled)\n",
        "    score_test = mean_squared_error(y_test, predictions, squared=False)  # RMSE calculation\n",
        "    print(f'RMSE on test data: {score_test}.')\n",
        "\n",
        "    # Append the best results to the df\n",
        "    hpo_results = hpo_results.append({'regressor_name': regressor_name,\n",
        "                                      'best_cv_score': best_cv_score,\n",
        "                                      'runtime_hpo': best_time,\n",
        "                                      'best_params': best_params,\n",
        "                                      'test_rmse': score_test}, ignore_index=True)\n",
        "\n",
        "# Mark the end of the entire pipeline\n",
        "hpo_time_end = time.time()\n",
        "print()\n",
        "print('######################################################################')\n",
        "print(f'The duration of the entire HPO pipeline for {len(df_best_regression)} classifiers across {n_trials} trials each: ')\n",
        "print(f'{round(hpo_time_end - hpo_time_start, 5)} seconds')\n",
        "\n",
        "# Sort the model results by test RMSE and then Runtime\n",
        "hpo_results = hpo_results.sort_values(['test_rmse', 'runtime_hpo'], ascending=[1, 0]).reset_index(drop=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2QWSKfJYXs8",
        "outputId": "98cd87b7-e459-403a-c1ec-6a2cfc41c0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Using *Linear Regression* for estimation.\n",
            "----------------------------------------------------------------------\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.3718505836595213\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}\n",
            "Time until beating the baseline: 2.7224s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.3717298266246012\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': False, 'n_jobs': 4, 'positive': False}\n",
            "Time until beating the baseline: 8.1831s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.371721356717252\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': False, 'n_jobs': -1, 'positive': False}\n",
            "Time until beating the baseline: 49.675s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.3716820797497892\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': False, 'n_jobs': -1, 'positive': False}\n",
            "Time until beating the baseline: 87.2504s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.3716778080416707\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': False, 'n_jobs': -1, 'positive': False}\n",
            "Time until beating the baseline: 112.2736s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.37162348300275205\n",
            "Parameter combination: {'copy_X': True, 'fit_intercept': True, 'n_jobs': 4, 'positive': False}\n",
            "Time until beating the baseline: 118.3406s\n",
            "*Linear Regression* BEAT THE BASELINE of 0.3288!\n",
            "Better CV score: -0.37161931165579615\n",
            "Parameter combination: {'copy_X': False, 'fit_intercept': True, 'n_jobs': 4, 'positive': False}\n",
            "Time until beating the baseline: 568.8765s\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [10:42<00:00,  3.21s/trial, best loss: 0.37161931165579615]\n",
            "\n",
            "######################################################################\n",
            "Best CV score in 200 iterations: -0.37161931165579615 (568.8765s until found).\n",
            "RMSE on test data: 0.3297358895957552.\n",
            "\n",
            "######################################################################\n",
            "The duration of the entire HPO pipeline for 1 classifiers across 200 trials each: \n",
            "642.18482 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-fae40cf15a9c>:109: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  hpo_results = hpo_results.append({'regressor_name': regressor_name,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column which says if the classifier beat the baseline\n",
        "hpo_results['beats_bl'] = np.where(hpo_results.loc[:,'test_rmse'] < best_baseline_score, 'yes', 'no')\n",
        "hpo_results.to_csv('hpo_results_rmse_lr.csv', index=False)\n",
        "# See the HPO results\n",
        "hpo_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "XR_TAp8eYXqP",
        "outputId": "492d9871-96aa-46b3-accb-b36a566b3bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      regressor_name  best_cv_score  runtime_hpo  \\\n",
              "0  Linear Regression      -0.371619     568.8765   \n",
              "\n",
              "                                         best_params  test_rmse beats_bl  \n",
              "0  {'copy_X': False, 'fit_intercept': True, 'n_jo...   0.329736       no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4db2b9fb-3a3c-4a9e-ae26-1e8769a218fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>regressor_name</th>\n",
              "      <th>best_cv_score</th>\n",
              "      <th>runtime_hpo</th>\n",
              "      <th>best_params</th>\n",
              "      <th>test_rmse</th>\n",
              "      <th>beats_bl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>-0.371619</td>\n",
              "      <td>568.8765</td>\n",
              "      <td>{'copy_X': False, 'fit_intercept': True, 'n_jo...</td>\n",
              "      <td>0.329736</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4db2b9fb-3a3c-4a9e-ae26-1e8769a218fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4db2b9fb-3a3c-4a9e-ae26-1e8769a218fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4db2b9fb-3a3c-4a9e-ae26-1e8769a218fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://github.com/qetdr/xAutoML-Project1/blob/main/project1_notebook.ipynb"
      ],
      "metadata": {
        "id": "sGc_wh7YC5wf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hETrW5g2C9Jl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}